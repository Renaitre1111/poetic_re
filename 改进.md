延续RAG+LM+RL的思路

明确问题：测试的时候对训练集的属性值拟合分布，然后随机在分布中进行采样

对于RAG，我们不再采用原先property-based方法，首先采用pretrained EGNN，将训练集的3D分子输入取最后一层embedding，然后训练一个cVAE，输出属性值和embedding，输出embedding，考虑到QM9数据集的属性分布不均匀，在这里采用resample的方法来降低imbalance的影响，训练完后随机采样P个噪声，对decoder输入噪声和属性值，解码得到P个分子embedding，然后利用k-means聚类，得到K个簇中心，簇中心的embedding与训练集的分子计算cosine similarity，取相似度最高的分子作为reference，得到K个来分别作为前缀保证多样性。

对于RAG得到的属性前缀，mamba的hidden维度是768，我们采用mlp1将目标属性值映射到768维，再将reference属性值和目标属性值的差值也通过mlp1映射到768维，将reference分子的embedding也映射到768维，然后把reference的token序列也拼接上去，前缀的构成就是属性embedding + delta embedding + reference embedding + reference token embedding。

LM 训练使用正常的交叉熵损失$Loss_{\text{cross}}$，不过我们还增加一个辅助损失，取mamba最后一个token的embedding，用mlp映射到1维作为属性值，然后计算和目标属性值的差值作为$Loss_{\text{delta}}$，最终的损失$Loss = Loss_{\text{cross}} + \lambda Loss_{\text{delta}}$

RL的修改就是把reward增加一个多样性的惩罚


